# Text-Mining-Natural-Language-Processing--using-NLTK
8 different text files(each a book) were imported into python and parsing the text data to a Structured form. Into a matrix in this case.
Tokenization, Removal of stop words, Tagging parts of speech to each term, stemming the terms to get the root word for each term was done.
total number of terms extracted from each of the 8 files.
Count for each unique term was derived.
A table of top 20 most common terms is made.
