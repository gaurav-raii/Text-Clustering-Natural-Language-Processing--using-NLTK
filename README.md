# Text-Mining-Natural-Language-Processing--using-NLTK
8 different text files(each a book) were imported into python and the text was parsed into a structured form. Into a list of lists in this case.
Tokenization, Removal of stop words, Tagging parts of speech to each term, stemming the terms to map them to the root word for each term was done.
total number of terms extracted from each of the 8 files.
Count for each unique term was derived.
A table of top 20 most common terms is made.
